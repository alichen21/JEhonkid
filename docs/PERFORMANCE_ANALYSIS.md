# 文本处理性能分析

## 问题描述
第二步文本处理特别慢，需要分析原因并优化。

## 当前实现分析

### 1. 处理流程
```
OCR识别 → 文本处理(LLM) → TTS生成
```

### 2. 文本处理步骤 (`text_processor.py`)
1. **构建 Prompt** - 将OCR文本包装成LLM提示词
2. **调用 LLM API** - 请求 `space.ai-builders.com` 的 `grok-4-fast` 模型
3. **解析响应** - 从LLM返回中提取结构化数据

### 3. 性能瓶颈分析

#### 可能的原因：

1. **LLM API 响应慢** ⚠️ (最可能)
   - 当前超时设置：60秒（已从30秒增加到60秒）
   - API服务器可能负载高或网络延迟
   - 模型 `grok-4-fast` 可能并不"fast"

2. **Prompt 过长**
   - 如果OCR文本很长，prompt也会很长
   - 长prompt会导致LLM处理时间增加

3. **同步阻塞**
   - 虽然是后台线程，但仍然是同步调用
   - 如果API慢，会阻塞整个线程

4. **max_tokens 限制**
   - 当前设置为2000，如果输出被截断可能需要重试

5. **网络延迟**
   - 请求外部API，网络质量影响响应时间

## 已添加的性能监控

### 监控指标
- ✅ 输入文本长度
- ✅ Prompt 长度
- ✅ LLM API 调用时间
- ✅ 响应解析时间
- ✅ 总处理时间
- ✅ LLM 响应长度

### 日志输出示例
```
[文本处理] 开始处理，输入文本长度: 150 字符
[文本处理] Prompt 长度: 450 字符
[文本处理] 开始调用 LLM API (模型: grok-4-fast)...
[文本处理] LLM API 调用完成，耗时: 15.23 秒
[文本处理] LLM 响应长度: 800 字符
[文本处理] 响应解析耗时: 0.05 秒
[文本处理] 总耗时: 15.28 秒
```

## 优化建议

### 1. 短期优化（已实现）
- ✅ 增加超时时间：30秒 → 60秒
- ✅ 添加详细的性能监控日志
- ✅ 记录各步骤耗时

### 2. 中期优化建议

#### 2.1 优化 Prompt
- 简化prompt，减少不必要的说明
- 使用更简洁的格式要求
- 考虑使用few-shot examples

#### 2.2 文本预处理
- 如果OCR文本过长，可以先进行简单清理
- 移除明显的噪音（如连续空格、特殊字符）
- 限制输入文本长度（如超过1000字符时截断）

#### 2.3 增加 max_tokens
- 如果经常遇到截断，可以增加到3000-4000
- 但要注意成本增加

#### 2.4 使用更快的模型
- 如果 `grok-4-fast` 仍然慢，考虑：
  - 使用更小的模型
  - 尝试其他API提供商
  - 使用本地模型（如果有）

### 3. 长期优化建议

#### 3.1 异步处理
- 使用 `asyncio` 和 `aiohttp` 实现异步API调用
- 避免阻塞线程

#### 3.2 缓存机制
- 对相同的OCR文本进行缓存
- 使用Redis或内存缓存

#### 3.3 批量处理
- 如果有多个任务，可以批量调用API
- 但需要注意API限制

#### 3.4 流式响应
- 如果API支持流式响应，可以边生成边返回
- 提升用户体验

#### 3.5 降级策略
- 如果LLM API超时或失败，使用规则引擎作为备选
- 简单的文本清理和分段可以用正则表达式实现

## 如何诊断问题

### 1. 查看日志
运行应用后，查看控制台输出的性能日志：
- 如果 `LLM API 调用时间` 很长（>10秒），说明API慢
- 如果 `响应解析时间` 很长，说明解析逻辑有问题
- 如果 `Prompt 长度` 很大（>2000字符），考虑优化prompt

### 2. 测试不同长度的文本
- 短文本（<100字符）：应该很快
- 中等文本（100-500字符）：正常速度
- 长文本（>500字符）：可能较慢

### 3. 检查网络
```bash
# 测试API响应时间
curl -X POST https://space.ai-builders.com/backend/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"grok-4-fast","messages":[{"role":"user","content":"test"}]}' \
  -w "\n时间: %{time_total}秒\n"
```

## 预期性能

### 理想情况
- 短文本（<100字符）：2-5秒
- 中等文本（100-500字符）：5-15秒
- 长文本（>500字符）：15-30秒

### 如果超过预期
1. 检查API服务状态
2. 检查网络连接
3. 考虑使用更快的模型或API
4. 实现缓存机制

## 下一步行动

1. ✅ 添加性能监控（已完成）
2. 🔄 运行测试，收集性能数据
3. ⏳ 根据数据决定优化方向
4. ⏳ 实施优化措施

